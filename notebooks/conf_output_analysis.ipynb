{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "\n",
    "from recsysconfident.data_handling.post_processing import Processing\n",
    "\n",
    "\n",
    "def solve_normal_pdf(mu: float, std: float, estimation: float) -> float | None:\n",
    "\n",
    "    def equation(x):\n",
    "        return x - norm.pdf(x, loc=mu, scale=std) # x - normal_pdf(x, mu, sigma) = 0\n",
    "\n",
    "    result = estimation\n",
    "    try:\n",
    "        solution = root_scalar(equation, bracket=[-10*std + estimation, 10*std + estimation], method='brentq')\n",
    "        if solution.converged:\n",
    "            result = solution.root\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    return result\n",
    "\n",
    "def double_line(x, mean=0):\n",
    "    return np.abs(x - mean)\n",
    "\n",
    "def open_error_conf_dfs(root_dir: str, split_name: str=\"test\", k_instance: int=4) -> dict:\n",
    "\n",
    "    test_conf_dfs = dict()\n",
    "\n",
    "    for sub_folder in os.listdir(root_dir):\n",
    "        \n",
    "        for csv_uri in glob.glob(f\"{root_dir}/{sub_folder}/**.csv\"):\n",
    "\n",
    "            csv_name = f\"{split_name}_error_conf-{k_instance}.csv\"\n",
    "            if csv_name in csv_uri:\n",
    "\n",
    "                setup = json.loads(open(f\"{root_dir}/{sub_folder}/setup-{k_instance}.json\").read())\n",
    "                metrics = json.loads(open(f\"{root_dir}/{sub_folder}/metrics-{k_instance}.json\").read())\n",
    "\n",
    "                error_conf_df = pd.read_csv(csv_uri).dropna()\n",
    "                postprocessing = Processing(setup['rate_range'])\n",
    "                error_conf_df = postprocessing.parse_clip_shift(error_conf_df, setup.get(\"abs_shift_conf\", False))\n",
    "                \n",
    "                error_conf_df.sort_values(by='conf_pred', inplace=True)\n",
    "                error_conf_df.loc[:, \"error\"] = np.abs(error_conf_df['rating'] - error_conf_df['r_pred'])\n",
    "                \n",
    "                if not setup['database_name'] in test_conf_dfs.keys():\n",
    "                    test_conf_dfs[setup['database_name']] = {}\n",
    "                \n",
    "                model_name = setup['model_name'].replace(\"mf-clustering\", \"mf-cluster\").replace(\"mf-non-reg\", \"mf-not-reg\")\n",
    "                test_conf_dfs[setup['database_name']][model_name] = {\n",
    "                            \"df\": error_conf_df,\n",
    "                            \"ranking\": metrics\n",
    "                        }\n",
    "                \n",
    "    return test_conf_dfs\n",
    "\n",
    "def thresholds(data: dict):\n",
    "    \n",
    "    result_df = data['df']\n",
    "    if not data['ranking'].get(\"eval_conf_threshold@10\", None):\n",
    "        C_T10 = solve_normal_pdf(result_df['conf_pred'].mean(),\n",
    "                                           result_df['conf_pred'].std(),\n",
    "                                           result_df['conf_pred'].quantile(0.98))\n",
    "        C_T3 = C_T10\n",
    "    else:\n",
    "        C_T10 = data['ranking'].get(\"eval_conf_threshold@10\", result_df['conf_pred'].quantile(0.9))\n",
    "        C_T3 = data['ranking'].get(\"eval_conf_threshold@3\", result_df['conf_pred'].quantile(0.9))\n",
    "    \n",
    "    return C_T10, C_T3\n",
    "\n",
    "def plot_tensors(x, y, C_T10, C_T3, xlabel=\"x\", ylabel=\"y\", ax=None):\n",
    "    ax.scatter(x, y, color='green')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    #ax.axvline(x=C_T10, color='red', linewidth=3)\n",
    "    #ax.axvline(x=C_T3, color='orange', linewidth=3)\n",
    "    #ax.set_xlim(0, 1)  # Fix x-axis range to [0, 1]\n",
    "    ax.grid(True)\n",
    "\n",
    "def plot_error_conf(grouped_data: dict, split_type: str, models_names: list[str]):\n",
    "    # Group data by prefix\n",
    "\n",
    "    plt.rcParams.update({'font.size': 30})\n",
    "\n",
    "    # Plot each group of datasets in a single row of subplots\n",
    "    for dataset_name, dataset_info in grouped_data.items():\n",
    "        n = len(models_names)\n",
    "        fig, axes = plt.subplots(1, n, figsize=(8 * n, 6))  # Adjust size for multiple plots\n",
    "        if n == 1:\n",
    "            axes = [axes]  # Ensure axes is iterable if only one plot\n",
    "        \n",
    "        print(dataset_name)\n",
    "        \n",
    "        for ax, model_name in zip(axes, models_names):\n",
    "            data = dataset_info[model_name.lower()]\n",
    "            result_df = data['df']\n",
    "\n",
    "            confs = result_df['conf_pred'].values\n",
    "            \n",
    "            C_T10, C_T3 = thresholds(data)\n",
    "                \n",
    "            plot_tensors(\n",
    "                confs,\n",
    "                result_df['error'],\n",
    "                C_T10,\n",
    "                C_T3,\n",
    "                \"Confidence\",\n",
    "                \"Error\",\n",
    "                ax=ax,\n",
    "            )\n",
    "            ax.set_title(model_name.replace(f\"{dataset_name}-\", \"\"))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./plots/error-conf-{dataset_name}-{split_type}.png\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_dist(confidence_arr, axes, i):\n",
    "\n",
    "    mean, std = np.mean(confidence_arr), np.std(confidence_arr)\n",
    "    x_values = np.linspace(min(confidence_arr), max(confidence_arr), 1000)\n",
    "    pdf_values = norm.pdf(x_values, mean, std)\n",
    "\n",
    "    # Plot histogram and KDE\n",
    "    axes[i].plot(x_values, pdf_values, color='orange', linewidth=2)\n",
    "\n",
    "def plot_distributions_horizontally(datasets: list[dict], fig_name: str, models: list[str]):\n",
    "    \"\"\"\n",
    "    Plot the 'conf_pred' distributions horizontally for each dataset, allowing individual y-axis scaling.\n",
    "\n",
    "    Parameters:\n",
    "        datasets (list): A list of dictionaries with keys \"df\" (dataframe) and \"name\" (dataset name).\n",
    "    \"\"\"\n",
    "    num_datasets = len(models)\n",
    "    fig, axes = plt.subplots(1, num_datasets, figsize=(6 * num_datasets, 6), dpi=300)  # Removed sharey=True\n",
    "\n",
    "    # Ensure `axes` is iterable even if there's only one subplot\n",
    "    if num_datasets == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, name in enumerate(models):\n",
    "        df = datasets[name.lower()][\"df\"]\n",
    "        confidence_arr = df[\"conf_pred\"].values\n",
    "\n",
    "        sns.histplot(confidence_arr, kde=True, color='blue', bins=30, stat=\"density\", ax=axes[i])\n",
    "\n",
    "        # Compute the Gaussian PDF\n",
    "        #plot_dist(confidence_arr, axes, i)\n",
    "\n",
    "        # Plot the confidence line\n",
    "        #sorted_array = np.sort(confidence_arr)\n",
    "        #axes[i].plot(sorted_array, sorted_array, color='orange', linewidth=2, )\n",
    "        \n",
    "        #C_T10, C_T3 = thresholds(data)\n",
    "        #axes[i].axvline(x=C_T10, color='red', linewidth=3)\n",
    "        #axes[i].axvline(x=C_T3, color='orange', linewidth=3)\n",
    "        \n",
    "        # Add labels, legend, and grid\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].set_xlabel(\"Confidence\")\n",
    "        axes[i].set_ylabel(\"Density\")\n",
    "        #axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./plots/{fig_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplots_horizontally(datasets: list[dict], plot_name: str, models: list[str]):\n",
    "\n",
    "    num_datasets = len(models)\n",
    "    fig, axes = plt.subplots(1, num_datasets, figsize=(6 * num_datasets, 4), dpi=300)\n",
    "\n",
    "    if num_datasets == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, name in enumerate(models):\n",
    "        df = datasets[name.lower()][\"df\"]\n",
    "        confidence_arr = df[\"conf_pred\"].values\n",
    "\n",
    "        sns.boxplot(x=confidence_arr, ax=axes[i], color='lightblue')\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].set_xlabel(\"Confidence\")\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./plots/{plot_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_conf_error_corr_bar(data, plot_name: str):\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Ensure each row is treated individually by resetting the index and pivoting by row\n",
    "    pivot_df = pd.DataFrame([df['conf_error_corr'].values], columns=df['name'].values)\n",
    "    pivot_df.columns.name = None  # Remove label 'name'\n",
    "\n",
    "    plt.figure(figsize=(pivot_df.shape[1] * 2.5, 3))\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        pivot_df,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap='vlag',\n",
    "        linewidths=.5,\n",
    "        linecolor='black',\n",
    "        annot_kws={\"fontsize\": 12},\n",
    "        vmin=-1,  # Set lower bound for color scale\n",
    "        vmax=0\n",
    "    )\n",
    "\n",
    "    # Remove title and color bar label\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.yaxis.label.set_size(12)\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./plots/{plot_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def obtain_models_corr(test_results_dict: dict, model_names: list[str]):\n",
    "\n",
    "    models_corr = dict()\n",
    "\n",
    "    for dataset in test_results_dict.keys():\n",
    "\n",
    "        models_results = test_results_dict[dataset]\n",
    "\n",
    "        for model_name in model_names:\n",
    "            model_result = models_results[model_name.lower()]\n",
    "            df_model_conf_error_df = model_result['df']\n",
    "            conf_error_corr = np.corrcoef(df_model_conf_error_df['conf_pred'], df_model_conf_error_df['abs_error'])[0, 1]\n",
    "\n",
    "            if not dataset in models_corr:\n",
    "                models_corr[dataset] = []\n",
    "\n",
    "            models_corr[dataset].append({\n",
    "                \"name\": model_name,\n",
    "                \"conf_error_corr\": conf_error_corr\n",
    "            })\n",
    "    return models_corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef769ef0b1961afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_instance = 0\n",
    "group_name = \"distribution_based\"\n",
    "model_names = ['ORDREC', \"CPMF\", \"CBPMF\", \"LBD\"]\n",
    "#model_names = [\"CPGAT\"]\n",
    "test_results_dict = open_error_conf_dfs(f\"../runs/{group_name}\", k_instance=k_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff170a62237c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_conf(test_results_dict, \"test\", model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de582b9849d049cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in test_results_dict.keys():\n",
    "\n",
    "    print(f\"{dataset}\")\n",
    "    plot_distributions_horizontally(test_results_dict[dataset], f\"{group_name}-{dataset}-test\", model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbba0ebdc0655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in test_results_dict.keys():\n",
    "\n",
    "    print(f\"{dataset}\")\n",
    "    plot_boxplots_horizontally(test_results_dict[dataset], f\"box-plot-{group_name}-{dataset}-test\", model_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1694ec9f64a6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tables_folds = []\n",
    "for k_instance in range(0, 5):\n",
    "    test_results_dict = open_error_conf_dfs(f\"../runs/{group_name}\", k_instance=k_instance)\n",
    "\n",
    "    models_corr = obtain_models_corr(test_results_dict, model_names)\n",
    "    corr_table_df = []\n",
    "\n",
    "    for database_name in models_corr.keys():\n",
    "        df = pd.DataFrame(models_corr[database_name]).T\n",
    "        df.columns = df.loc['name']\n",
    "        df.drop(\"name\", axis=0, inplace=True)\n",
    "        df.index = [database_name]\n",
    "        corr_table_df.append(df)\n",
    "\n",
    "    corr_tables_folds.append(pd.concat(corr_table_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382737053a0d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.concat(corr_tables_folds)\n",
    "group_corr_df = corr_df.reset_index().groupby(by='index')\n",
    "mean_corr_df = group_corr_df.mean()\n",
    "std_df_corr_df = group_corr_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b003dcf535ce527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coor_latex_table(mean_df: pd.DataFrame, std_df: pd.DataFrame, caption: str, label: str, columns: list):\n",
    "    mean_df = mean_df.copy().astype(float).round(4)\n",
    "    std_df = std_df.copy().astype(float).round(4)\n",
    "\n",
    "    combined_df = pd.DataFrame(index=mean_df.index)\n",
    "\n",
    "    for idx in mean_df.index:\n",
    "        row = mean_df.loc[idx, columns]\n",
    "        min_value = row.min()\n",
    "\n",
    "        for col in columns:\n",
    "            mean_val = mean_df.loc[idx, col]\n",
    "            std_val = std_df.loc[idx, col]\n",
    "            formatted = f\"{mean_val:.4f} ± {std_val:.4f}\"\n",
    "\n",
    "            if mean_val == min_value:\n",
    "                formatted = f\"\\\\textbf{{{formatted}}}\"\n",
    "\n",
    "            combined_df.loc[idx, col] = formatted\n",
    "\n",
    "    combined_df = combined_df.reset_index().rename(columns={\"index\": \"database\"})\n",
    "    combined_df = combined_df[[\"database\"] + columns]\n",
    "\n",
    "    latex_code = combined_df.to_latex(\n",
    "        label=label,\n",
    "        caption=caption,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        column_format=\"c\" * len(combined_df.columns)\n",
    "    )\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65b0a3c60a15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_coor_latex_table(mean_corr_df, std_df_corr_df, \"Confidence correlation with error.\", \"tab:corr_error_distribution_based\", model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0120a2bf3b9a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsysconfident-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
